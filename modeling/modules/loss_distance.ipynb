{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8fe84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as f\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "from scipy.ndimage import distance_transform_edt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8963309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_csf_distance_map(csf_mask: torch.Tensor, spacing=None) -> torch.Tensor:\n",
    "  device = csf_mask.device\n",
    "  csf_np = csf_mask.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "  B = csf_np.shape[0]\n",
    "  dist_maps = []\n",
    "\n",
    "  for b in range(B):\n",
    "    csf_slice = csf_np[b,0]\n",
    "    dt = distance_transform_edt(2.0 - csf_slice, sampling=spacing)\n",
    "    dist_maps.append(dt)\n",
    "\n",
    "  dist_maps = np.stack(dist_maps, axis=0)\n",
    "  dist_maps = torch.from_numpy(dist_maps).to(device=device, dtype=torch.float32)\n",
    "  dist_maps = dist_maps.unsqueeze(1)\n",
    "  print()\n",
    "  print(\"=== CSF Maps ===\")\n",
    "  print(csf_mask)\n",
    "\n",
    "  return dist_maps\n",
    "\n",
    "def clustering(loss_map):\n",
    "  numpy_arr = loss_map.squeeze().numpy()\n",
    "  labeled, num = nd.label(numpy_arr)\n",
    "  max_values = []\n",
    "  for i in range(1, num + 1):\n",
    "    region = numpy_arr[labeled == i]\n",
    "    # print(region)\n",
    "    # print()\n",
    "    max_values.append(region.max())\n",
    "  return max_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035b6b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSFDistanceLoss(nn.Module):\n",
    "  def __init__(self, sigma: float= 5.0, reduction: str=\"sum\"):\n",
    "    super().__init__()\n",
    "    self.sigma = sigma\n",
    "    # self.max_distance= max_distance\n",
    "    assert reduction in [\"mean\", \"sum\", \"none\"]\n",
    "    self.reduction = reduction\n",
    "\n",
    "  def forward(self, cmb_logits: torch.Tensor, gt_cmb: torch.Tensor, gt_csf: torch.Tensor, spacing=None) -> torch.Tensor:\n",
    "    device = cmb_logits.device\n",
    "    cmb_prob = torch.sigmoid(cmb_logits)\n",
    "    print(\"=== CMB Probability Maps ===\")\n",
    "    print(cmb_prob)\n",
    "    cmb_prob = cmb_prob * (cmb_prob > 0.6).float()      \n",
    "    print(cmb_prob)\n",
    "\n",
    "    dist_map = compute_csf_distance_map(gt_csf, spacing).to(device) # Distance Map for CSF\n",
    "    print(\"=== Distance Maps ===\")\n",
    "    print(dist_map)\n",
    "    print()\n",
    "       \n",
    "    weight = torch.exp(-dist_map / self.sigma)  # Distance map based weight\n",
    "    print(\"=== Weight Maps ===\")\n",
    "    print(weight)\n",
    "    print()\n",
    "    # if self.max_distance is not None:\n",
    "    #   far_mask = dist_map > self.max_distance # boolean numpy 2d ndarray\n",
    "    #   weight = weight * (~far_mask)\n",
    "\n",
    "    '''\n",
    "    filter for removing the true cmb regions.\n",
    "    It needs to be larger to fully avoid the true cmb predicted region.\n",
    "    '''\n",
    "    bg_mask = (gt_cmb==0).float()\n",
    "    # bg_mask = bg_mask * (gt_csf!=1.0).float()\n",
    "    print(\"=== Background Mask (to filter out true CMB regions) ===\")\n",
    "    print(bg_mask)\n",
    "    print()\n",
    "    fp_soft = cmb_prob * bg_mask # selecting only fp cases.\n",
    "\n",
    "    loss_map = fp_soft * weight\n",
    "    print(\"=== Loss Map ===\")\n",
    "    print(loss_map)\n",
    "    print()\n",
    "    max_values = clustering(loss_map)\n",
    "\n",
    "    print(\"=== Max values for each cluster ===\")\n",
    "    print(max_values)\n",
    "    print()\n",
    "    \n",
    "    print(\"=== Sum of max values for all clusters: FINAL DISTANCE LOSS ===\")\n",
    "    print(sum(max_values))\n",
    "    if self.reduction == \"mean\":\n",
    "      denom = (bg_mask * (weight > 0).float()).sum()\n",
    "      denom = torch.clamp(denom, min=1.0)\n",
    "      return loss_map.sum() / denom\n",
    "    elif self.reduction == \"sum\":\n",
    "      return sum(max_values)\n",
    "      # return loss_map.sum()\n",
    "    else:\n",
    "      return loss_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1453cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CMB Probability Maps ===\n",
      "tensor([[[[0.5250, 0.5498, 0.5744, 0.5987, 0.6225, 0.6548, 0.5987],\n",
      "          [0.5250, 0.7109, 0.5744, 0.5987, 0.6225, 0.6900, 0.6457],\n",
      "          [0.5250, 0.6682, 0.5744, 0.5987, 0.6225, 0.6457, 0.6682],\n",
      "          [0.5250, 0.5498, 0.5744, 0.5250, 0.5250, 0.5250, 0.5250],\n",
      "          [0.5250, 0.5498, 0.5744, 0.5250, 0.5250, 0.5250, 0.5250],\n",
      "          [0.7109, 0.6682, 0.5744, 0.5250, 0.5250, 0.5250, 0.5250],\n",
      "          [0.6900, 0.6457, 0.5744, 0.5250, 0.5250, 0.5250, 0.5250]]]])\n",
      "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.6225, 0.6548, 0.0000],\n",
      "          [0.0000, 0.7109, 0.0000, 0.0000, 0.6225, 0.6900, 0.6457],\n",
      "          [0.0000, 0.6682, 0.0000, 0.0000, 0.6225, 0.6457, 0.6682],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7109, 0.6682, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6900, 0.6457, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n",
      "\n",
      "=== CSF Maps ===\n",
      "tensor([[[[0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 0, 0],\n",
      "          [0, 0, 0, 0, 0, 2, 2],\n",
      "          [0, 0, 0, 0, 0, 2, 2],\n",
      "          [0, 0, 0, 0, 2, 2, 2],\n",
      "          [0, 0, 0, 0, 0, 0, 2],\n",
      "          [0, 0, 0, 0, 0, 2, 2]]]])\n",
      "=== Distance Maps ===\n",
      "tensor([[[[5.3852, 4.4721, 3.6056, 2.8284, 2.2361, 2.0000, 2.0000],\n",
      "          [5.0000, 4.1231, 3.1623, 2.2361, 1.4142, 1.0000, 1.0000],\n",
      "          [4.4721, 3.6056, 2.8284, 2.0000, 1.0000, 0.0000, 0.0000],\n",
      "          [4.1231, 3.1623, 2.2361, 1.4142, 1.0000, 0.0000, 0.0000],\n",
      "          [4.0000, 3.0000, 2.0000, 1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [4.1231, 3.1623, 2.2361, 1.4142, 1.0000, 1.0000, 0.0000],\n",
      "          [4.4721, 3.6056, 2.8284, 2.0000, 1.0000, 0.0000, 0.0000]]]])\n",
      "\n",
      "=== Weight Maps ===\n",
      "tensor([[[[0.3406, 0.4088, 0.4862, 0.5680, 0.6394, 0.6703, 0.6703],\n",
      "          [0.3679, 0.4384, 0.5313, 0.6394, 0.7536, 0.8187, 0.8187],\n",
      "          [0.4088, 0.4862, 0.5680, 0.6703, 0.8187, 1.0000, 1.0000],\n",
      "          [0.4384, 0.5313, 0.6394, 0.7536, 0.8187, 1.0000, 1.0000],\n",
      "          [0.4493, 0.5488, 0.6703, 0.8187, 1.0000, 1.0000, 1.0000],\n",
      "          [0.4384, 0.5313, 0.6394, 0.7536, 0.8187, 0.8187, 1.0000],\n",
      "          [0.4088, 0.4862, 0.5680, 0.6703, 0.8187, 1.0000, 1.0000]]]])\n",
      "\n",
      "=== Background Mask (to filter out true CMB regions) ===\n",
      "tensor([[[[1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1.],\n",
      "          [0., 1., 1., 1., 1., 1., 1.],\n",
      "          [0., 0., 1., 1., 1., 1., 1.],\n",
      "          [0., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1., 1., 1., 1.]]]])\n",
      "\n",
      "=== Loss Map ===\n",
      "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.3980, 0.4389, 0.0000],\n",
      "          [0.0000, 0.3117, 0.0000, 0.0000, 0.4691, 0.5649, 0.5286],\n",
      "          [0.0000, 0.3249, 0.0000, 0.0000, 0.5096, 0.6457, 0.6682],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3117, 0.3550, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2821, 0.3139, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])\n",
      "\n",
      "=== Max values for each cluster ===\n",
      "[0.66818774, 0.32488102, 0.3549985]\n",
      "\n",
      "=== Sum of max values for all clusters: FINAL DISTANCE LOSS ===\n",
      "1.3480672538280487\n"
     ]
    }
   ],
   "source": [
    "cmb_logits = torch.tensor([[[\n",
    "                    [0.1,0.2,0.3,0.4,0.5,0.64,0.4],\n",
    "                    [0.1,0.9,0.3,0.4,0.5,0.8,0.6],\n",
    "                    [0.1,0.7,0.3,0.4,0.5,0.6,0.7],\n",
    "                    [0.1,0.2,0.3,0.1,0.1,0.1,0.1],\n",
    "                    [0.1,0.2,0.3,0.1,0.1,0.1,0.1],\n",
    "                    [0.9,0.7,0.3,0.1,0.1,0.1,0.1],\n",
    "                    [0.8,0.6,0.3,0.1,0.1,0.1,0.1]]]])\n",
    "cmb_logits = cmb_logits.float()\n",
    "# gt_cmb = torch.zeros(1, 1, 7, 7)\n",
    "gt_cmb = torch.tensor([[[                \n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [1,0,0,0,0,0,0],\n",
    "                    [1,1,0,0,0,0,0],\n",
    "                    [1,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0]]]])\n",
    "\n",
    "gt_csf = torch.tensor([[[\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,2,2],\n",
    "                    [0,0,0,0,0,2,2],\n",
    "                    [0,0,0,0,2,2,2],\n",
    "                    [0,0,0,0,0,0,2],\n",
    "                    [0,0,0,0,0,2,2]]]])\n",
    "# gt_csf = torch.zeros(1, 1, 7, 7)\n",
    "\n",
    "bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "distance_loss_fn = CSFDistanceLoss(sigma=5.0, reduction=\"mean\")\n",
    "\n",
    "bce_loss = bce_loss_fn(cmb_logits, gt_cmb.float())\n",
    "distance_loss = distance_loss_fn(cmb_logits, gt_cmb, gt_csf, spacing=None)\n",
    "\n",
    "# Combine (lambda is a hyperparameter)\n",
    "lambda_dist = 0.5\n",
    "total_loss = bce_loss + lambda_dist * distance_loss\n",
    "# print(total_loss)\n",
    "\n",
    "# total_loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff21a6a",
   "metadata": {},
   "source": [
    "### Implementation Note V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a6ce73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss_Distance(nn.Module):\n",
    "    def __init__(self, batched_inputs, root_path, sigma_param):\n",
    "        super(Loss_Distance, self).__init__()\n",
    "        # self.outputs = outputs['batched_masks']\n",
    "        self.batched_inputs = batched_inputs\n",
    "        self.root_path = \"/media/Datacenter_storage/Ji/BiomedParse\"\n",
    "        self.csf_mask_path = os.path.join(self.root_path, batched_inputs[0][\"grounding_info\"][0][\"mask_file\"])\n",
    "        self.cmb_mask_path = self.csf_mask_path.replace(\"cerebrospinal+fluid\", \"brain_microbleeds\")\n",
    "        self.sigma = sigma_param\n",
    "\n",
    "    def forward(self, cmb_prob: torch.Tensor, csf_mask_path) -> torch.Tensor:\n",
    "        cmb_mask_path = csf_mask_path.replace(\"cerebrospinal+fluid\", \"brain+microbleeds\")\n",
    "        gt_csf = Image.open(csf_mask_path).convert('L')\n",
    "        gt_cmb = Image.open(cmb_mask_path).convert('L')\n",
    "        gt_csf = torch.from_numpy(np.array(gt_csf)).to(cmb_prob.device).unsqueeze(0).unsqueeze(0).float()\n",
    "        gt_cmb = torch.from_numpy(np.array(gt_cmb)).to(cmb_prob.device).unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "        # distance map from CSF (fixed wrt model => fine)\n",
    "        dist_map = compute_csf_distance_map(gt_csf).to(cmb_prob.device)\n",
    "\n",
    "        weight = torch.exp(-dist_map / self.sigma)   # Bx1xHxW\n",
    "\n",
    "        # background mask outside CMB\n",
    "        bg_mask = (gt_cmb == 0).float().to(cmb_prob.device)\n",
    "\n",
    "        # model prediction\n",
    "        cmb_prob = torch.sigmoid(cmb_prob)\n",
    "        # (optional) REMOVE hard threshold for better gradients:\n",
    "        # cmb_prob = cmb_prob * (cmb_prob > 0.6).float()\n",
    "\n",
    "        # resize prediction to match mask\n",
    "        cmb_prob = F.interpolate(cmb_prob, size=bg_mask.shape[2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        # false-positive \"soft\" map\n",
    "        fp_soft = cmb_prob * bg_mask  # only region where GT is not CMB\n",
    "\n",
    "        # distance-weighted loss\n",
    "        loss_map = fp_soft * weight\n",
    "\n",
    "        # final scalar loss (differentiable)\n",
    "        # loss_distance = loss_map.mean()\n",
    "        loss_distance = loss_map.sum() / torch.clamp((weight > 0).sum(), min=1.0)\n",
    "\n",
    "        # loss_distance = loss_map.sum()\n",
    "        return loss_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc05309",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batched_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# gt_csf = torch.zeros(1, 1, 7, 7)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m bce_loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss()\n\u001b[0;32m---> 31\u001b[0m distance_loss_func \u001b[38;5;241m=\u001b[39m Loss_Distance(\u001b[43mbatched_inputs\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/Datacenter_storage/Ji/BiomedParse\u001b[39m\u001b[38;5;124m\"\u001b[39m, sigma_param\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.0\u001b[39m)\n\u001b[1;32m     33\u001b[0m bce_loss \u001b[38;5;241m=\u001b[39m bce_loss_fn(cmb_logits, gt_cmb\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     34\u001b[0m distance_loss \u001b[38;5;241m=\u001b[39m distance_loss_fn(cmb_logits, gt_cmb, gt_csf, spacing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batched_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "cmb_logits = torch.tensor([[[\n",
    "                    [0.1,0.2,0.3,0.4,0.5,0.64,0.4],\n",
    "                    [0.1,0.9,0.3,0.4,0.5,0.8,0.6],\n",
    "                    [0.1,0.7,0.3,0.4,0.5,0.6,0.7],\n",
    "                    [0.1,0.2,0.3,0.1,0.1,0.1,0.1],\n",
    "                    [0.1,0.2,0.3,0.1,0.1,0.1,0.1],\n",
    "                    [0.9,0.7,0.3,0.1,0.1,0.1,0.1],\n",
    "                    [0.8,0.6,0.3,0.1,0.1,0.1,0.1]]]])\n",
    "cmb_logits = cmb_logits.float()\n",
    "# gt_cmb = torch.zeros(1, 1, 7, 7)\n",
    "gt_cmb = torch.tensor([[[                \n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [1,0,0,0,0,0,0],\n",
    "                    [1,1,0,0,0,0,0],\n",
    "                    [1,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0]]]])\n",
    "\n",
    "gt_csf = torch.tensor([[[\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,0,0],\n",
    "                    [0,0,0,0,0,1,1],\n",
    "                    [0,0,0,0,0,1,1],\n",
    "                    [0,0,0,0,1,1,1],\n",
    "                    [0,0,0,0,0,0,1],\n",
    "                    [0,0,0,0,0,1,1]]]])\n",
    "# gt_csf = torch.zeros(1, 1, 7, 7)\n",
    "\n",
    "bce_loss_fn = nn.BCEWithLogitsLoss()\n",
    "distance_loss_func = Loss_Distance(batched_inputs, \"/media/Datacenter_storage/Ji/BiomedParse\", sigma_param=10.0)\n",
    "\n",
    "bce_loss = bce_loss_fn(cmb_logits, gt_cmb.float())\n",
    "distance_loss = distance_loss_fn(cmb_logits, gt_cmb, gt_csf, spacing=None)\n",
    "\n",
    "# Combine (lambda is a hyperparameter)\n",
    "lambda_dist = 0.5\n",
    "total_loss = bce_loss + lambda_dist * distance_loss\n",
    "# print(total_loss)\n",
    "\n",
    "# total_loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea53731",
   "metadata": {},
   "source": [
    "### Implementation Note V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a1522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as f\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b197d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_csf_distance_map(csf_mask: torch.Tensor, spacing=None) -> torch.Tensor:\n",
    "  device = csf_mask.device\n",
    "  csf_np = csf_mask.detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "  B = csf_np.shape[0]\n",
    "  dist_maps = []\n",
    "\n",
    "  for b in range(B):\n",
    "    csf_slice = csf_np[b,0]\n",
    "    dt = distance_transform_edt(1.0 - csf_slice, sampling=spacing)\n",
    "    dist_maps.append(dt)\n",
    "\n",
    "  dist_maps = np.stack(dist_maps, axis=0)\n",
    "  dist_maps = torch.from_numpy(dist_maps).to(device=device, dtype=torch.float32)\n",
    "  dist_maps = dist_maps.unsqueeze(1)\n",
    "  print(\"=== CSF Maps ===\")\n",
    "  print(csf_mask)\n",
    "  return dist_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e21ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512])\n",
      "torch.Size([1, 1, 512, 512])\n",
      "=== CSF Maps ===\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "=== Distance Maps ===\n",
      "tensor([[[[222.9125, 222.1463, 221.3820,  ..., 224.0893, 224.8488, 225.6103],\n",
      "          [222.2724, 221.5040, 220.7374,  ..., 223.4390, 224.2008, 224.9644],\n",
      "          [221.6348, 220.8642, 220.0954,  ..., 222.7914, 223.5554, 224.3212],\n",
      "          ...,\n",
      "          [187.4887, 186.6574, 185.8279,  ..., 180.6239, 181.4718, 182.2581],\n",
      "          [188.0452, 187.2164, 186.3867,  ..., 181.1574, 182.0027, 182.8497],\n",
      "          [188.6054, 187.7711, 186.9358,  ..., 181.6948, 182.5377, 183.3821]]]],\n",
      "       device='cuda:0')\n",
      "\n",
      "=== Weight Maps ===\n",
      "tensor([[[[4.3457e-20, 5.0654e-20, 5.9020e-20,  ..., 3.4344e-20,\n",
      "           2.9504e-20, 2.5336e-20],\n",
      "          [4.9393e-20, 5.7598e-20, 6.7142e-20,  ..., 3.9114e-20,\n",
      "           3.3587e-20, 2.8829e-20],\n",
      "          [5.6110e-20, 6.5460e-20, 7.6340e-20,  ..., 4.4523e-20,\n",
      "           3.8215e-20, 3.2788e-20],\n",
      "          ...,\n",
      "          [5.1873e-17, 6.1255e-17, 7.2309e-17,  ..., 2.0474e-16,\n",
      "           1.7281e-16, 1.4766e-16],\n",
      "          [4.6409e-17, 5.4775e-17, 6.4663e-17,  ..., 1.8402e-16,\n",
      "           1.5540e-16, 1.3118e-16],\n",
      "          [4.1490e-17, 4.9024e-17, 5.7938e-17,  ..., 1.6527e-16,\n",
      "           1.3963e-16, 1.1793e-16]]]], device='cuda:0')\n",
      "\n",
      "=== Background Mask (to filter out true CMB regions) ===\n",
      "bg_mask\n",
      "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          ...,\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
      "          [1., 1., 1.,  ..., 1., 1., 1.]]]])\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m cmb_prob \u001b[38;5;241m=\u001b[39m cmb_prob \u001b[38;5;241m*\u001b[39m (cmb_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.6\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     46\u001b[0m fp_soft \u001b[38;5;241m=\u001b[39m cmb_prob \u001b[38;5;241m*\u001b[39m bg_mask \u001b[38;5;66;03m# selecting only fp cases.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m loss_map \u001b[38;5;241m=\u001b[39m \u001b[43mfp_soft\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Loss Map ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_map)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (512) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "csf_mask_path = \"/media/Datacenter_storage/Ji/BiomedParse/biomedparse_datasets/loss_dev/train_mask/sub-207-slice-108_MRI_Brain_cerebrospinal+fluid.png\"\n",
    "cmb_mask_path = csf_mask_path.replace(\"cerebrospinal+fluid\", \"brain+microbleeds\")\n",
    "gt_csf = Image.open(csf_mask_path).convert('L')\n",
    "gt_cmb = Image.open(cmb_mask_path).convert('L')\n",
    "gt_csf = np.array(gt_csf)\n",
    "gt_cmb = np.array(gt_cmb)\n",
    "\n",
    "gt_csf = torch.from_numpy(gt_csf)\n",
    "gt_cmb = torch.from_numpy(gt_cmb)\n",
    "\n",
    "gt_csf = gt_csf.unsqueeze(0).unsqueeze(0).float()\n",
    "gt_cmb = gt_cmb.unsqueeze(0).unsqueeze(0).float()\n",
    "\n",
    "print(gt_csf.shape)\n",
    "print(gt_cmb.shape)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dist_map = compute_csf_distance_map(gt_csf).to(device) # Distance Map for CSF\n",
    "print(\"=== Distance Maps ===\")\n",
    "print(dist_map)\n",
    "print()\n",
    "\n",
    "sigma = 5.0\n",
    "weight = torch.exp(-dist_map / sigma)  # Distance map based weight\n",
    "print(\"=== Weight Maps ===\")\n",
    "print(weight)\n",
    "print()\n",
    "\n",
    "# bg_mask = bg_mask * (gt_csf!=1.0).float()\n",
    "print(\"=== Background Mask (to filter out true CMB regions) ===\")\n",
    "bg_mask = (gt_cmb==0).float()\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "bg_mask = F.interpolate(bg_mask, size=(256, 256), mode='nearest')\n",
    "print(\"bg_mask\")\n",
    "print(bg_mask)\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "cmb_prob = torch.rand([1,101,256, 256])\n",
    "cmb_prob = torch.sigmoid(cmb_prob)\n",
    "cmb_prob = cmb_prob * (cmb_prob > 0.6).float()\n",
    "fp_soft = cmb_prob * bg_mask # selecting only fp cases.\n",
    "\n",
    "loss_map = fp_soft * weight\n",
    "print(\"=== Loss Map ===\")\n",
    "print(loss_map)\n",
    "print()\n",
    "max_values = clustering(loss_map)\n",
    "\n",
    "print(\"=== Max values for each cluster ===\")\n",
    "print(max_values)\n",
    "print()\n",
    "\n",
    "print(\"=== Sum of max values for all clusters: FINAL DISTANCE LOSS ===\")\n",
    "print(sum(max_values))\n",
    "\n",
    "reduction = \"sum\"\n",
    "if reduction == \"mean\":\n",
    "    denom = (bg_mask * (weight > 0).float()).sum()\n",
    "    denom = torch.clamp(denom, min=1.0)\n",
    "    # return loss_map.sum() / denom\n",
    "elif reduction == \"sum\":\n",
    "    return sum(max_values)\n",
    "# return loss_map.sum()\n",
    "else:\n",
    "    return loss_map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomedparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
